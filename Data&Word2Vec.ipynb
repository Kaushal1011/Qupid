{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "published-specific",
   "metadata": {},
   "source": [
    "# Notebook about the research done on retrieving data for word2vec embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-diving",
   "metadata": {},
   "source": [
    "## Trying to find related words using twitter tweet search api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-purpose",
   "metadata": {},
   "source": [
    "## Define all base terms for which we want to search tweets for that may come in member profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sublime-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=[\"Programmer\",\"Coding\",\"Javascript\",\"Cloud Computing\",\"Manager\",\"Finance\",\"Design\",\"Art\",\"Dribbble\",\"Github\",\"Python\",\"Data\",\"Science\",\"Commerce\",\"Machine Learning\",\\\n",
    "      \"Engineer\",\"IBM\",\"Chartered Accountant\",\"Figma\",\"Adobe\",\"Music\",\"Audio\",\"Language\",\"Vocabulary\",\"Designer\",\"Coder\",\"Mathematician\",\"Creative\",\"Logic\",\"Logical\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "speaking-dodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Programmer',\n",
       " 'Coding',\n",
       " 'Javascript',\n",
       " 'Cloud Computing',\n",
       " 'Manager',\n",
       " 'Finance',\n",
       " 'Design',\n",
       " 'Art',\n",
       " 'Dribbble',\n",
       " 'Github',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'Commerce',\n",
       " 'Machine LearningEngineer',\n",
       " 'IBM',\n",
       " 'Chartered Accountant',\n",
       " 'Figma',\n",
       " 'Adobe',\n",
       " 'Music',\n",
       " 'Audio',\n",
       " 'Language',\n",
       " 'Vocabulary',\n",
       " 'Designer',\n",
       " 'Coder',\n",
       " 'Mathematician',\n",
       " 'Creative',\n",
       " 'Logic',\n",
       " 'Logical']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-voice",
   "metadata": {},
   "source": [
    "### Twitter API sample code\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def auth():\n",
    "    return os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "def create_url():\n",
    "    query = \"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    tweet_fields = \"tweet.fields=author_id\"\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query={}&{}\".format(\n",
    "        query, tweet_fields\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def main():\n",
    "    bearer_token = auth()\n",
    "    url = create_url()\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extended-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def create_url(query):\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "#     tweet_fields = \"tweet.fields=author_id\"\n",
    "    #max_results=100\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "        query\n",
    "    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intermediate-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    return \"AAAAAAAAAAAAAAAAAAAAAC6vMwEAAAAA5uumFGxBM1e4Kfyfr8E5TJseEZw%3DHV6mjkDp1QrpVm1bpi2yZrvAEkpqhxCK91fGkjl5gevPwtLScM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "specified-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for i in terms:\n",
    "    bearer_token = auth()\n",
    "    url = create_url(i)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "#     print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    with open(i+'_data.json', 'w') as f:\n",
    "        json.dump(json_response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-floor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
